# Overview
This project investigates solving the coordination problem in _sequential social dilemmas_ (SSDs) by generating and applying social norms that are generated by a hierarchy of LLMs model. Specifically, the objective is to achieve high social welfare in SSDs by use of a meta-norm that is robust across different configurations/layouts of an environment. This repo is a fork of the Deepmind's [Meltingpot](https://github.com/google-deepmind/meltingpot).

Norms desribes the incentive structure of a _multi-agent system_ (MAS) in terms of permissions, obligations and prohibitions. Policies can reinforce or create new norms, but they are _exogenous_ forces that shape multi-agent behaviour. This means that it is important to articulate norms carefully because, once established, they are embedded in the social or strategic structure of a multi-agent system. Unlike policies, norms are sustained _endogenously_ and so poorly specified or overfitted norms may prove fragile and prone to collapse. It is therefore important to design (organizational) norms that are robust, a fundamental liimitation of these being the ability to search and simulate within the policy space.

This project uses a modified version of the _commons_harvest__open_ substrate to investigate the capability of _large language models_ (LLMs) to do this. Using text description of the game and relevant information, we can leverage the demonstrated ability of LLMs to think strategically to evaluate payoffs and model a norm in code, which can then be plugged in directly to the simulation framework and tested.

# Overview

# Installation
You first need to have **Python 3.11.9** installed. You can check this is the case by entering the following from the terminal, within the file directory. To then install all required packages, run the code below in bash.

```bash
pip install -r requirements.txt
```
TO DO:
- Clean up ReadME with clear description of installation, file structure and scope of project
- Need to clarify what precisely the objective of project is on paper (robust meta norms? cross environment performance? Framework for optimising norms?)
- LLM needs to be linked into the simualtion for seamless integration of meta norm generated
- Need data clearly showing comparison of norm against heuristic
- Need to implement independent RL agent / altruistic agent baseline
