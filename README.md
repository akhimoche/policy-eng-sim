# Overview
This project investigates solving the coordination problem in sequential social dilemmas (SSDs) by generating and applying social norms that are generated by a hierarchy of LLMs model. Specifically, the objective is to achieve high social welfare in SSDs by use of a meta-norm that is robust across different configurations/layouts of an environment. This repo is a fork of the Deepmind's Meltingpot.

Policies can reinforce or create new norms, but they are exogenous forces that shape multi-agent behaviour. This means that it is important to articulate policies carefully because, once established, they are embedded in the social or strategic structure of a multi-agent system. 

This project uses a modified version of the commons_harvest__open substrate to investigate the capability of large language models (LLMs) to do this in the form of constraint generation. Using text description of the game and relevant information, we can leverage the demonstrated ability of LLMs to think strategically to evaluate payoffs and model high level meta-strategies in the form of constraint schedules, which can then be plugged in directly to the simulation framework and tested.

# Installation
You first need to have Python 3.11.9 installed. You can check this is the case by entering the following from the terminal, within the file directory. To then install all required packages, run the code below in bash.

```
pip install -r requirements.txt
```
TO DO:
- Clean up ReadME with clear description of installation, file structure and scope of project
- Need to clarify what precisely the objective of project is on paper (robust meta norms? cross environment performance? Framework for optimising norms?)
- LLM needs to be linked into the simualtion for seamless integration of meta norm generated
- Need data clearly showing comparison of norm against heuristic
- Need to implement independent RL agent / altruistic agent baseline
