# Overview
This project investigates solving the coordination problem in sequential social dilemmas (SSDs) by generating and applying social norms that are generated by a hierarchy of LLMs model. Specifically, the objective is to achieve high social welfare in SSDs by use of a meta-norm that is robust across different configurations/layouts of an environment. This repo is a fork of the Deepmind's Meltingpot.

Norms desribes the incentive structure of a multi-agent system (MAS) in terms of permissions, obligations and prohibitions. Policies can reinforce or create new norms, but they are exogenous forces that shape multi-agent behaviour. This means that it is important to articulate norms carefully because, once established, they are embedded in the social or strategic structure of a multi-agent system. Unlike policies, norms are sustained endogenously and so poorly specified or overfitted norms may prove fragile and prone to collapse. It is therefore important to design (organizational) norms that are robust, a fundamental liimitation of these being the ability to search and simulate within the policy space.

This project uses a modified version of the commons_harvest__open substrate to investigate the capability of large language models (LLMs) to do this. Using text description of the game and relevant information, we can leverage the demonstrated ability of LLMs to think strategically to evaluate payoffs and model a norm in code, which can then be plugged in directly to the simulation framework and tested.

# Installation
You first need to have Python 3.11.9 installed. You can check this is the case by entering the following from the terminal, within the file directory. To then install all required packages, run the code below in bash.

```
pip install -r requirements.txt
```

